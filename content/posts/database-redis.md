---
title: "Database：Redis 设计与实现"
author: "Chenghao Zheng"
tags: ["Database"]
categories: ["Reading notes"]
date: 2021-05-08T13:19:47+01:00
draft: false
---

Redis 是一个开源的，内存中的数据结构存储系统，它可以用作数据库、缓存和消息中间件，支持多种类型的数据结构和范围查询。 Redis 内置了复制（replication）、事务（transactions）和不同级别的磁盘持久化（persistence），并通过 Redis哨兵（Sentinel）和自动分区（Cluster）提供高可用性（high availability）。

本篇将结合 [《Redis 设计与实现》](https://book.douban.com/subject/25900156/) 讲解 Redis 的内部机制、单机特性以及多机特性。

### Redis 数据结构

Redis 有五种不同的 **对象类型**，包括字符串、列表、哈希、集合和有序集合，每种对象都用到了至少一种数据结构，这样就可以根据不同的使用场景，为对象设置不同的数据结构（内部编码）实现，从而优化对象在不同场景下的使用效率。

![](/images/redis-data-structure.jpg)

如上图所示，可以看到每种数据结构都有 2 种以上的 **内部编码实现**，例如 String 数据结构就包含了 raw、int 和 embstr 三种内部编码。同时，有些内部编码可以作为多种外部数据结构的内部实现，例如 ziplist 就是 hash、list 和 zset 共有的内部编码，而 set 的内部编码可能是 hashtable 或者 intset。

Redis 使用对象来表示数据库中的键和值，每次当我们在 Redis 数据库中新创建一个键值对时，我们至少会创建两个对象，一个键对象，一个值对象。每个对象都由一个 `redisObject` 结构表示：

~~~c
typedef struct redisObject {
	unsigned type : 4;        // 类型
	unsigned encoding : 4;    // 编码
	void *ptr;                // 指向底层实现数据结构的指针
	// ...
} robj;
~~~

因为 C 语言并不具备自动内存回收功能，所以 Redis 在自己的对象系统中构建了一个 **引用计数** 技术实现的内存回收机制。对象的引用计数属性还带有 **对象共享** 的作用，不仅字符串键可以使用共享对象，那么在数据结构中嵌套了字符串对象的对象都可以使用这些共享对象。

#### 字符串

Redis 中的字符串对象是 **可以修改** 的，称为 SDS `Simple Dynamic String`，简单动态字符串。它有三种不同的编码实现：int、raw、embstr。当一个 key 的 value 是整型时，Redis 就将其编码为 int 类型，这种编码类型节省了内存。Redis 默认会缓存 10000 个整型值（#define OBJSHAREDINTEGERS 10000），这就意味着，如果有 10 个不同的 KEY，其 value 都是 10000 以内的值，事实上全部都是 **共享同一个对象**。

~~~shell
127.0.0.1:6379> set msg 9999
OK
127.0.0.1:6379> object encoding msg
"int"
127.0.0.1:6379> set msg hello
OK
127.0.0.1:6379> object encoding msg
"embstr"
127.0.0.1:6379> set story "long, long, long ago there lived a king."
OK
127.0.0.1:6379> strlen story
(integer) 40
127.0.0.1:6379> object encoding story
"raw"
~~~

`embstr` 和 raw 编码的长度界限是 39，长度超过 39 字节以后，就是 raw 编码类型。embstr 编码将创建字符串对象所需的 **空间分配的次数** 从 raw 编码的两次降低为一次。因为 embstr 编码的字符串对象的所有数据都保存在一块连续的内存里面，所以这种编码的字符串对象比起 raw 编码的字符串对象能更好地利用缓存带来的优势，并且释放 embstr 编码的字符串对象只需要调用一次内存释放函数，而释放 raw 编码对象的字符串对象需要调用两次内存释放函数。

raw 编码的 SDS 数据结构如下：

~~~~C
struct sdshdr {
 int len;    // buf 数组中已使用的字节数量
 int free;   // buf 数组中未使用的字节数量
 char buf[];
}
~~~~

相比 C 字符串，SDS 具有以下优点：

1. O(1) 复杂度获取字符串长度，C 字符串需要遍历获取，复杂度为 0(N)
2. 杜绝了因忘记重分配内存而导致的缓冲区溢出
3. 通过 **空间预分配**（小于 1MB，分配 2 * len + 1，大于等于 1MB 分配 1MB 的未使用空间）
和 **惰性空间释放**（free 记录未使用空间代替内存回收）减少了修改字符串时所需的 **内存重分配** 次数
4. 使用 len 属性值而不是空字符判断结尾，可以保存任意格式的二进制数据
5. 兼容部分 C 字符串函数

#### 列表

列表对象的编码可以是 ziplist 或者 linkedlist。`linkedlist` 就是我们非常熟悉的双向链表，特征有：双端、无环、带表头和表尾指针、带长度计数器、多态。当列表保存的所有字符串元素长度都小于 64 字节，并且列表长度小于 512 时，列表使用 `ziplist` 编码：

```shell
127.0.0.1:6379> rpush numbers 1 three 5
(integer) 3
127.0.0.1:6379> type numbers
list
127.0.0.1:6379> object encoding numbers
"ziplist"
```

压缩列表是 Redis 为了 **节约内存** 而开发的，是由一系列特殊编码的连续内存块组成的顺序型数据结构，其结构为：

`<zlbytes><zltail><zllen><entry><entry> ... <entry><zlend>`

| 属性    | 长度(字节) | 用途                                                         |
| :------ | :--------- | :----------------------------------------------------------- |
| zlbytes | 4          | 表示这个 ziplist 占用了多少字节，其中包括了 zlbytes 本身占用的 4 个字节：在对压缩列表进行内存重分配，或者计算 zlend 的位置时使用 |
| zltail  | 4          | 表示到 ziplist 中最后一个元素的偏移量，有了这个值，pop 操作的时间复杂度就是 O(1) 了，即不需要遍历整个 ziplist |
| zllen   | 2          | 表示 ziplist 中有多少个 entry，即保存了多少个元素。由于这个字段占用 16 位，所以最大值是2^16-1，当这个值等于 UNIT16_MAX(65535) 时，节点的真实数量需要遍历整个压缩列表才能计算得出 |
| entryX  | 不定       | 压缩列表包含的各个节点，节点的长度由保存的内存决定           |
| zlend   | 1          | 特殊值 0xFF(255)，用于标记压缩列表的末端                     |

每个压缩列表节点都是由 previous_entry_length、encoding、content 三个部分组成，`previous_entry_length` 记录了前一个节点的长度，程序可以通过指针运算，根据当前节点的起始地址来 **计算出前一个节点的起始地址**，从而实现从表尾向表头遍历。如果前一个节点的长度小于 254 字节，那么 previous_entry_length 会使用 1 字节记录它的长度，如果前一节点的长度大于等于 254 字节，那么 previous_entry_length 的长度为 5 字节，且属性的第一个字节会被设置为 0xFE(254)，之后四个字节则用于保存前一节点的长度。`encoding` 属性记录了节点的 content 所存数据的类型及长度，节点值 `content` 可以是一个字节数据或者整数。

如果在一个压缩列表中，有多个连续的、长度介于 250 字节到 253 字节之前的节点 e1 至 eN，这时将一个长度大于等于 254 字节的新节点 new 设置为压缩列表的表头节点就会触发 **连锁更新**。如下图所示，因为 e1 的 previous_entry_length 属性仅长 1 字节，它没办法保存新节点 new 的长度，所以程序将对压缩列表执行空间重分配操作，并将 e1 的 previous_entry_length属性从原来的 1 字节长扩展为 5 字节长。但这又导致了 e2 的 previous_entry_length 无法记录 e1 的长度，导致需要再次执行空间重分配操作...

![](/images/redis-list-chain-update.jpg)

除了添加新节点可能会引发连锁更新之外，删除节点也可能会引发连锁更新。在最坏的情况下需要对压缩列表执行 N 次空间重分配操作，而每次空间重分配的最坏复杂度为 O(N)，所以连锁更新的最坏复杂度为 O(N^2)。尽管连锁更新的复杂度较高，但它真正造成性能问题的 **几率是很低的**，压缩列表里要恰好有多个连续的、长度介于 250 字节至 253 字节之间的节点，才有可能引发连锁更新；即使出现连锁更新，但只要被更新的节点数量不多，就不会对性能造成任何影响，所以 ziplistPush 等命令的平均复杂度仅为O(N)。

#### 哈希

哈希对象的编码可以是 ziplist 或者 hashtable。当哈希对象保存的所有键值对的键和值的字符串长度都小于 64 字节，且保存的键值对数量小于 512 个，哈希对象就使用 `ziplist` 编码，每当有新的键值对要加入到哈希对象时，程序会先将保存了键的节点推入压缩列表表尾，再将保存了值的节点推入到压缩列表表尾，如下图所示：

![](/images/redis-hashmap-ziplist.jpg)

当上述的两个条件不满足时，哈希对象就会使用 hashtable 编码，由于 Redis 所使用的 C 语言 **没有内置** 字典这种数据结构，因此 Redis 构建了自己的字典实现，其结构如下图所示：

![](/images/redis-hashmap-dicht.jpg)

`dicht` 中的 table 指向一个数组，数组中的每个元素都指向一个 `dictEntry` 结构，它保存着一个键值对。dictEntry 包含指向另一个哈希表节点的指针，这个指针可以将多个哈希值相同的键值对连接在一起，以此来解决 **键冲突** 的问题。`ht` 是一个包含两个项的数组，数组中的每个项都是一个 dicht 哈希表，一般情况下，字典只使用 ht[0] 哈希表，ht[1] 哈希表只会在对 ht[0] 哈希表进行 rehash 时使用。

Redis 中字典的 rehash 动作并不是一次性、集中式地完成的，而是 **分多次、渐进式** 地完成的。因为如果哈希表里保存的键值对数量较多，要一次性将这些键值对全部 rehash 到 ht[1] 的话，庞大的计算量可能会导致服务器在一段时间内 **停止服务**。渐进式 rehash 时会在字典内维护一个索引计数器变量 rehashidx，在 rehash 进行期间，程序会将 ht[0] 哈希表在 rehashidx 索引上的所有键值对 rehash 到 ht[1]，当本次 rehash 完成后，程序将 rehashidx 属性的值加一。

在进行渐进式 rehash 的过程中，字典会同时使用 ht[0] 和 ht[1] 两个哈希表，删除、查找、更新等操作会在两个哈希表上进行。例如要在字典里面查找一个键的话，程序会先在 ht[0] 里面进行查找，如果没找到的话，就会继续到 ht[1] 里面进行查找，诸如此类。新添加到字典的键值对一律会被保存到 ht[1] 里面，而 ht[0] 则不再进行任何添加操作，这一措施保证了 ht[0] 包含的键值对数量会 **只减不增**，并随着 rehash 操作的执行而最终变成空表。

#### 集合

集合对象的编码可以是 intset 或者 hashtable，当集合对象保存的元素都是整数值且元素数量不超过 512 个时将会使用整数集合编码，不满足这两个条件就使用 hashtable 编码，字典的每个键都是一个集合元素，而字典的值则全部被设置为 NULL。

`Contents` 数组的每一项都是整数集合的一个元素，各个项在数组中按值的大小从小到大有序地排列，并且数组中不包含任何重复项。intset 的结构如下图所示：

![](/images/redis-intset.jpg)

其中的 encoding 决定了集合中整数的类型，它可以是 INTSET_ENC_INT8、INTSET_ENC_INT16、INTSET_ENC_INT32、INTSET_ENC_INT64，每当我们要将一个新元素添加到整数集合里面，并且新元素的类型比集合中的现有类型长时，整数集合需要先进行 **升级**。升级时会先扩展整数集合底层数组的空间大小，然后将现有元素都转换成与新元素相同的类型，最后将新元素添加到底层数组里面。

因为 C 语言是静态类型语言，为了避免 **类型错误**，我们通常不会将两种不同类型的值放在同一个数据结构里面。整数集合通过自动升级底层数据来适应新元素，所以我们可以随意地将 int16_t、int32_t 或者 int64_t 类型的整数添加到集合中，而不必担心出现类型错误。整数集合的实现可以让集合可以尽量节省内存，又可以确保升级操作只会在有需要的时候进行。

#### 有序集合

有序集合 Sorted Set 的编码可以是 zipllist 或 skiplist，当有序集合保存的所有元素成员的长度都小于 64 字节且元素数量小于 128 个时会使用 ziplist 编码，每个集合元素使用两个紧挨在一起的压缩列表节点来保存，第一个节点保存元素的成员，第二个元素保存元素的分值，如下图所示：

![](/images/redis-sortedSet-ziplist.jpg)

跳跃表 skiplist 是一种有序的数据结构，它通过在每个节点中维持 **多个指向其他节点的指针**，从而达到快速访问节点的目的。其结构如下图所示，header 和 tail 为支持快速访问的表头节点和表尾节点，level 用于获取跳跃表中层高最大的那个节点的数量（表头节点的层高并不计算在内）。表中的节点按各自所保存的分值从小到大排列，节点的 level 数组可以包含多个元素，每个元素都包含一个指向其他节点的指针，程序可以通过这些层来加快访问其他节点的速度。

![](/images/redis-skiplist-hashtable.jpg)

除此之外，有序集合还同时使用字典来保存从成员到分值的映射，这样就可以以 O(1) 复杂度查找给定成员的分值。值得一提的是，虽然 zset 结构同时使用跳跃表和字典来保存有序集合元素，但这两种数据结构都会通过指针来 **共享** 相同元素的成员和分值，不会产生任何重复成员或者分值，也不会因此而 **浪费额外的内存**。

# 单机数据库的实现

### 数据库

Redis 使用字典类型的 **键空间 dict**  保存数据库中的键和值，其结构如下图所示。每次当我们在 Redis 数据库中新创建一个键值对时，我们至少会创建两个对象，一个字符串键对象，一个值对象，它可以是字符串对象、列表对象、哈希表对象、集合对象和有序集合对象中的一种。

![](/images/redis-dict.jpg)

因为 Redis 的键空间是一个字典，所以所有针对数据库的操作，比如添加或删除一个键值对，又或者在数据库中获取某个键值对等，实际上都是通过对键空间进行操作来实现的。

通过 `EXPIRE` 或者 `PEXPIRE` 命令可以以秒或者毫秒精度为某个键设置生存时间，或者通过 `EXPIREAT` 或 `PEXPIREAT` 命令给某个键设置过期时间（UNIX 时间戳）。Redis 通过 **expires 字典** 保存数据库中所有键的过期时间，它的键指向间空间中的某个键对象（对象共享），值为一个毫秒精度的 long long 类型的 UNIX 时间戳。

![](/images/redis-expire.jpg)

通过过期字典，程序可以检查某个键是否存在于过期字典，如果存在，可以检查当前 UNIX 时间错是否大于键的过期时间，如果是的话，那么键已经过期；否则键未过期。如果一个键过期了，那么它什么时候会被删除呢？

* 定时删除：设置键的过期时间的同时，创建一个定时器，在键的过期时间来临时立即执行对键的删除操作。定时删除策略是 **对内存最友好** 的，可以保证过期键会尽可能快地被删除，并释放过期键所占用的内存，但它 **对 CPU 时间是最不友好** 的，在 CPU 时间非常紧张的情况下，这无疑会对服务器的响应时间和吞吐量造成影响。

* 惰性删除：每次从键空间获取键时，都检查键是否过期，如果过期就删除。这样对 CPU 时间来说是最友好的，因为删除过期键的操作只会在非做不可的情况下进行，且只删除当前处理的键；但它 **对内存是最不友好的**，有些过期键如果没被访问到的话可能永远也不会被删除（内存泄漏），这对于运行状态非常依赖于内存的 Redis 服务器来说，肯定不是一个好消息。

* 定期删除：每隔一段时间，程序就对数据库进行一次检查，删除里面的过期键。定期删除策略是前两种策略的一种整合和折中，每隔一段时间执行一次删除过期键操作，并通过限制操作执行的时长和频率来减少删除操作对 CPU 时间的影响，此外，定期删除有效地减少了因为过期键而带来的内存浪费。

Redis 服务器实际使用的是惰性删除和定期删除两种策略：通过配合使用这两种删除策略，服务器可以很好地在合理使用 CPU 时间和避免浪费内存空间之间取得 **平衡**。

### RDB 持久化

Redis 提供了 RDB 持久化功能将内存中的数据库状态保存到磁盘里面，来避免进程退出时数据库状态的意外丢失。RDB 可以手动执行，也可以根据服务器配置定期执行，它会生成一个经过压缩的二进制文件，在 Redis 启动时可以用 RDB 文件来还原数据库状态。

`SAVE` 命令会 **阻塞** 服务器进程，直到 RDB 文件创建完毕，在这期间服务器不能处理任何命令请求。`BGSAVE` 则会在派生出的子进程中创建 RDB 文件，服务器进程（父进程）继续处理命令请求。

save 选项的默认条件为：

> save 900 1
>
> save 300 10
>
> save 60 10000

那么只要满足以下三个条件中的任意一个，BGSAVE 命令就会被执行：

* 服务器在 900 秒之内，对数据库进行了至少 1 次修改
* 服务器在 300 秒之内，对数据库进行了至少 10 次修改
* 服务器在 60 秒之内，对数据库进行了至少 10000 次修改

Redis 通过其周期性操作函数 `serverCron` 默认每隔 100 毫秒执行一次检查，检查 dirty 计数器并计算距离上次执行保存操作有多少秒，当满足保存条件中的任意一条时便执行 BGSAVE 命令。

在创建新的 RDB 文件时，程序会对数据库中的键进行检查，**已过期的键** 不会被保存到新创建的 RDB 文件中。在 Redis 启动载入 RDB 文件时，程序会对文件中保存的键进行检查，未过期的键会被载入到数据库中，而过期键则会被忽略，所以过期键对载入 RDB 文件的服务器不会造成影响。

Redis 在启动时会自动检测，如果存在 RDB 文件就会自动载入。值得一提的是，因为 AOF 文件的 **更新频率** 通常比 RDB 文件的要高，所以如果服务器开启了 AOF 持久化功能，那 Redis 会优先使用 AOF 文件来还原数据库状态。只有在 AOF 持久化功能处于关闭状态时，服务器才会使用 RDB 文件来还原数据库状态。

### AOF 持久化

除了 RDB 之外，Redis 还提供了 AOF `Append Only File` 持久化功能。AOF 通过保存 Redis 服务器所执行的 **写命令** 来记录数据库状态的，服务器在执行完一个写命令之后，会以协议格式将被执行的写命令追加到服务器状态的 aof_buf 缓冲区的末尾，由服务器配置的 `appendfsync`（默认为 everysec）来决定不同的持久化行为：

| appendfsync | 持久化行为                                                   |
| ----------- | ------------------------------------------------------------ |
| always      | 将 aof_buf 缓冲区中的所有内容写入并同步到 AOF 文件中         |
| everysec    | 将 aof_buf 缓冲区中的所有内容写入到 AOF 文件，如果距上次同步超过一秒，就进行同步 |
| no          | 将 aof_buf 缓冲区中的所有内容写入到 AOF 文件，不进行同步，何时同步由操作系统来决定 |

当 appendfsync 的值为 always 时，服务器在每个事件循环都要将 aof_buf 缓冲区中的所有内容写入到 AOF 文件，并且同步 AOF 文件，效率最慢但也 **最安全**，即使出现故障停机，AOF 持久化也只会丢失一个事件循环中所产生的命令数据。Redis 在载入 AOF 文件进行数据还原时会创建一个不带网络连接的伪客户端，逐条读取其中的写命令并执行。

随着服务器的运行，AOF 文件中的内容会越来越多，文件的体积也会越来越大，如果不加以控制的话，体积过大的 AOF文件很可能对 Redis 服务器、甚至整个宿主计算器造成影响，并且 AOF 文件的体积越大，进行数据还原所需的时间就越多。

为此，Redis 提供了 **AOF 文件重写** 功能，通过创建一个不包含任何浪费空间的冗余命令的新的 AOF 文件来替换原有的 AOF 文件。AOF 文件重写并不需要对现有的 AOF 文件进行任何读取、分析或者写入操作，而是通过读取服务器当前的数据库状态来实现的。因为新的 AOF 文件只包含还原当前数据库状态所必须的命令，所以新的 AOF 文件不会浪费任何硬盘空间。

Redis 将 AOF 重写放到子进程中执行，这样服务器进程（父进程）可以在重写期间继续处理命令请求。在此期间客户端对数据库的修改会被同时记录到 **AOF 重写缓冲区** 中，当子进程完成创建新 AOF 文件的工作之后，服务器会将重写缓冲区中的所有内容追加到新 AOF 文件的末尾，最后使用原子替换完成 AOF 重写操作。

![](/images/redis-aof-rewrite.jpg)

对于 **过期键**，当过期键被惰性删除或者定期删除之后，程序会向 AOF 文件追加一条 DEL 命令，来显式地记录该键已被删除。在 AOF 重写的过程中，已过期的键不会被保存到重写后的 AOF 文件中，因此数据库中包含过期键不会对 AOF 产生影响。

### 事件



# 多机数据库的实现

### 复制

### Sentinel

### 集群

# Redis 功能

### 发布与订阅

### 事务

### 排序